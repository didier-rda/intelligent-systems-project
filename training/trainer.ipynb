{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rural-panama",
   "metadata": {},
   "source": [
    "### Created by: Rodrigo Didier, 01/31/21."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-principle",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "combined-saver",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-embassy",
   "metadata": {},
   "source": [
    "# DATA SCIENCE PIPLINE --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-camel",
   "metadata": {},
   "source": [
    "# 0. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-injury",
   "metadata": {},
   "source": [
    "# 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "speaking-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data_path = os.getenv('DATASET_PATH')\n",
    "        self.data = self.extractData()\n",
    "\n",
    "    def extractData(self):\n",
    "        '''\n",
    "        Loads a dataset with product data from a specified path.\n",
    "        '''\n",
    "\n",
    "        return pd.read_csv(self.data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-portable",
   "metadata": {},
   "source": [
    "#  2. Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "optical-transition",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y), (X_test, y_test), (X_val, y_val)= dataFormatter().split_train_test_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "european-validation",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, Series found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-536a0f08afcb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concatenated_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3826\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3827\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3828\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mapply_if_callable\u001b[0;34m(maybe_callable, obj, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \"\"\"\n\u001b[1;32m    328\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-536a0f08afcb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_text\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concatenated_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, Series found"
     ]
    }
   ],
   "source": [
    "    X.assign(full_text= lambda row: ' '.join([row['query'], row['title'], row['concatenated_tags']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "living-camcorder",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, method found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-fbc7dd664277>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenated_tags\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, method found"
     ]
    }
   ],
   "source": [
    " ' '.join([X.query, X.title, X.concatenated_tags])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "standard-fundamentals",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sequence item 0: expected str instance, StringMethods found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-554a953c2e7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'query'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'concatenated_tags'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: sequence item 0: expected str instance, StringMethods found"
     ]
    }
   ],
   "source": [
    "' '.join([X['query'].str, X['title'].str, X['concatenated_tags'].str])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "annoying-tongue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7917                        leque de madeira\n",
       "33016                   adesivo de parede 3d\n",
       "31923              caixa papel personalizada\n",
       "11067                       tapete bem vindo\n",
       "28087       capa para caderneta de vacinacao\n",
       "                        ...                 \n",
       "6622     lembrancinhas de maternidade menino\n",
       "35187                               trocador\n",
       "31132    lembrancinhas de maternidade em eva\n",
       "37527                              sacolinha\n",
       "23841             roupas de cachorro atacado\n",
       "Name: query, Length: 30400, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "objective-train",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot broadcast np.ndarray with operand of type <class 'method'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpressions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;31m# error: \"None\" not callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_evaluate_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/computation/expressions.py\u001b[0m in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/roperator.py\u001b[0m in \u001b[0;36mradd\u001b[0;34m(left, right)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mradd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'method' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-2f3c69b097e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/common.py\u001b[0m in \u001b[0;36mnew_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/arraylike.py\u001b[0m in \u001b[0;36m__radd__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__radd__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__radd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__sub__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   4957\u001b[0m         \u001b[0mlvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4958\u001b[0m         \u001b[0mrvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_numpy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4959\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4961\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36marithmetic_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mres_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_na_arithmetic_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0;31m#  will handle complex numbers incorrectly, see GH#32047\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_masked_arith_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_cmp\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/ops/array_ops.py\u001b[0m in \u001b[0;36m_masked_arith_op\u001b[0;34m(x, y, op)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0;34mf\"Cannot broadcast np.ndarray with operand of type { type(y) }\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             )\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot broadcast np.ndarray with operand of type <class 'method'>"
     ]
    }
   ],
   "source": [
    "X.query + X.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "particular-appliance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>seller_id</th>\n",
       "      <th>query</th>\n",
       "      <th>search_page</th>\n",
       "      <th>position</th>\n",
       "      <th>title</th>\n",
       "      <th>concatenated_tags</th>\n",
       "      <th>creation_date</th>\n",
       "      <th>price</th>\n",
       "      <th>weight</th>\n",
       "      <th>express_delivery</th>\n",
       "      <th>minimum_quantity</th>\n",
       "      <th>view_counts</th>\n",
       "      <th>order_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7917</th>\n",
       "      <td>4142514</td>\n",
       "      <td>6080672</td>\n",
       "      <td>leque de madeira</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Leques de madeira Envio Expresso 5 dias úteis</td>\n",
       "      <td>casamento leques</td>\n",
       "      <td>2016-08-21 14:17:14</td>\n",
       "      <td>14.220000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>220</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33016</th>\n",
       "      <td>6363203</td>\n",
       "      <td>2417318</td>\n",
       "      <td>adesivo de parede 3d</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>Papel de Parede 3D Paisagem Cachoeira 0019</td>\n",
       "      <td>papel parede 3d cachoeira papel parede parede</td>\n",
       "      <td>2018-05-03 14:44:22</td>\n",
       "      <td>62.699997</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9960</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31923</th>\n",
       "      <td>6432298</td>\n",
       "      <td>971052</td>\n",
       "      <td>caixa papel personalizada</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Caixa personalizada de Nossa Senhora com vidro...</td>\n",
       "      <td>religiosos</td>\n",
       "      <td>2018-09-09 16:05:42</td>\n",
       "      <td>39.940000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11067</th>\n",
       "      <td>2661983</td>\n",
       "      <td>6024256</td>\n",
       "      <td>tapete bem vindo</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>Tapete croche bem vindo mesclado pink</td>\n",
       "      <td>decoracao primavera tapetes porta decorar tape...</td>\n",
       "      <td>2017-02-12 20:18:51</td>\n",
       "      <td>110.270000</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>146</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28087</th>\n",
       "      <td>291711</td>\n",
       "      <td>2335174</td>\n",
       "      <td>capa para caderneta de vacinacao</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>Capa para Caderneta de Vacinação</td>\n",
       "      <td>capas cadernetas vacinacao cartao vacina leona...</td>\n",
       "      <td>2017-05-22 16:26:07</td>\n",
       "      <td>59.910000</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>205</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       product_id  seller_id                             query  search_page  \\\n",
       "7917      4142514    6080672                  leque de madeira            1   \n",
       "33016     6363203    2417318              adesivo de parede 3d            1   \n",
       "31923     6432298     971052         caixa papel personalizada            2   \n",
       "11067     2661983    6024256                  tapete bem vindo            1   \n",
       "28087      291711    2335174  capa para caderneta de vacinacao            1   \n",
       "\n",
       "       position                                              title  \\\n",
       "7917          3      Leques de madeira Envio Expresso 5 dias úteis   \n",
       "33016        14         Papel de Parede 3D Paisagem Cachoeira 0019   \n",
       "31923         3  Caixa personalizada de Nossa Senhora com vidro...   \n",
       "11067        19              Tapete croche bem vindo mesclado pink   \n",
       "28087        20                   Capa para Caderneta de Vacinação   \n",
       "\n",
       "                                       concatenated_tags        creation_date  \\\n",
       "7917                                    casamento leques  2016-08-21 14:17:14   \n",
       "33016      papel parede 3d cachoeira papel parede parede  2018-05-03 14:44:22   \n",
       "31923                                         religiosos  2018-09-09 16:05:42   \n",
       "11067  decoracao primavera tapetes porta decorar tape...  2017-02-12 20:18:51   \n",
       "28087  capas cadernetas vacinacao cartao vacina leona...  2017-05-22 16:26:07   \n",
       "\n",
       "            price  weight  express_delivery  minimum_quantity  view_counts  \\\n",
       "7917    14.220000     9.0                 1                30          220   \n",
       "33016   62.699997     9.0                 0                 2         9960   \n",
       "31923   39.940000     0.0                 1                 4           52   \n",
       "11067  110.270000  1009.0                 0                 7          146   \n",
       "28087   59.910000   258.0                 0                 9          205   \n",
       "\n",
       "       order_counts  \n",
       "7917            1.0  \n",
       "33016          39.0  \n",
       "31923          20.0  \n",
       "11067           NaN  \n",
       "28087           2.0  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "funky-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataFormatter(dataExtractor):\n",
    "    def __init__(self):\n",
    "        self.extracted_data = dataExtractor().data\n",
    "        #self.train_data = self.formatData()[0]\n",
    "        #self.validation_data = self.formatData()[1]\n",
    "        \n",
    "    def formatData(self):\n",
    "        '''\n",
    "        Processes the dataset to use it for training and validation.\n",
    "        '''\n",
    "        \n",
    "        # add methods to formating the data to the  modeler.\n",
    "    \n",
    "    def categoryToDummy(self):\n",
    "        # get dummy\n",
    "        dummy = pd.get_dummies(self.extracted_data['category'])\n",
    "\n",
    "        # merge df\n",
    "        df_dummy = pd.merge(self.extracted_data, dummy, left_index=True, right_index=True)\n",
    "\n",
    "        # delet no dummy cols\n",
    "        del df_dummy['category']\n",
    "\n",
    "        return df_dummy\n",
    "    \n",
    "    def split_train_test_validate(self):\n",
    "        '''\n",
    "        Split the dataset into train, validation and test\n",
    "        '''\n",
    "        \n",
    "        # categorical variables list to split\n",
    "        y_cols = list(self.categoryToDummy().columns[-6:])\n",
    "        X_cols = list(self.categoryToDummy().columns[:-6])\n",
    "        \n",
    "        # full data categorized\n",
    "        y_data =  self.categoryToDummy()[y_cols] #.values\n",
    "        X_data =  self.categoryToDummy()[X_cols] #.values\n",
    "                \n",
    "        X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.2, train_size=0.8)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.25,train_size =0.75)\n",
    "        \n",
    "        return (X, y), (X_test, y_test), (X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "boolean-orleans",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "texto = 'João pé de feijão, foi correr e sentiu. Porém, seguiu! esse cara é fod* texto'\n",
    "sentencas = sent_tokenize(texto)\n",
    "palavras = word_tokenize(texto.lower())\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "stopwords = set(stopwords.words('portuguese') + list(punctuation))\n",
    "palavras_sem_stopwords = [palavra for palavra in palavras if palavra not in stopwords]\n",
    "\n",
    "from nltk.probability import FreqDist\n",
    "frequencia = FreqDist(palavras_sem_stopwords)\n",
    "\n",
    "#from collections import defaultdict\n",
    "#sentencas_importantes = defaultdict(int)\n",
    "\n",
    "#for i, sentenca in enumerate(sentencas):\n",
    "#    for palavra in word_tokenize(sentenca.lower()):\n",
    "#        if palavra in frequencia:\n",
    "#            sentencas_importantes[i] += frequencia[palavra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "formal-vehicle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'joão': 1, 'pé': 1, 'feijão': 1, 'correr': 1, 'sentiu': 1, 'porém': 1, 'seguiu': 1, 'cara': 1, 'fod': 1, 'texto': 1})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "chemical-resistance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "João pé de feijão, foi correr e sentiu.\n"
     ]
    }
   ],
   "source": [
    "from heapq import nlargest\n",
    "\n",
    "idx_sentencas_importantes = nlargest(1, sentencas_importantes, sentencas_importantes.get)\n",
    "\n",
    "for i in sorted(idx_sentencas_importantes):\n",
    "    print(sentencas[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as n\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-schema",
   "metadata": {},
   "source": [
    "# 3. Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "therapeutic-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataModeler(dataFormatter):\n",
    "    def __init__(self):\n",
    "        self.model = dataModeler.getModel()\n",
    "        self.train_data = dataFormatter.train_data\n",
    "        \n",
    "    def getModel():\n",
    "        '''\n",
    "        Specifies a model to handle the categorization problem.\n",
    "        # criar etapa de modelagem -métodos se for o caso\n",
    "        # dar split no train e treinar\n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "        model = None\n",
    "        return model\n",
    "        \n",
    "    def writeModel(self):\n",
    "        '''\n",
    "        Exports a candidate model to a specified path available\n",
    "        in the environment variable MODEL_PATH.\n",
    "        '''\n",
    "\n",
    "        # criar try: tenta salvar, se nao dá erro.\n",
    "    \n",
    "        return pickle.dump(self.model, open(os.getenv('MODEL_PATH'),'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-going",
   "metadata": {},
   "source": [
    "# 4. Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "electoral-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelValidator(dataModeler, dataFormatter):\n",
    "    def __init__(self):\n",
    "        self.model = self.readModel()\n",
    "        self.validation_data = dataFormatter.validation_data\n",
    "    \n",
    "    def readModel(self):\n",
    "        '''\n",
    "        get the model selected to handle the categorization problem.\n",
    "        '''\n",
    "        \n",
    "        # criar um try, se nao der entao dar um saveModel\n",
    "        \n",
    "        return pickle.load(open(os.getenv('MODEL_PATH'),'rb'))\n",
    "        \n",
    "    def validateModel(self):\n",
    "        '''\n",
    "        Generates metrics about the model accuracy (precision, recall, F1, etc.)\n",
    "        for each category and exports them to a specified path available in the \n",
    "        environment variable METRICS_PATH.\n",
    "        '''\n",
    "        # try k-fold and variants.\n",
    "        \n",
    "        # should save metrics in METRICS_PATH\n",
    "        f = open(os.getenv('METRICS_PATH'), \"w\")\n",
    "        f.write(\"F1:95.0, Precision:87.5\")\n",
    "        f.close()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-valve",
   "metadata": {},
   "source": [
    "# 5. Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concerned-technology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
