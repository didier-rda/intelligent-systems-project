{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rural-panama",
   "metadata": {},
   "source": [
    "### Created by: Rodrigo Didier, 01/31/21."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-principle",
   "metadata": {},
   "source": [
    "# Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-embassy",
   "metadata": {},
   "source": [
    "# DATA SCIENCE PIPLINE --------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-camel",
   "metadata": {},
   "source": [
    "# 0. Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-injury",
   "metadata": {},
   "source": [
    "# 1. Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "speaking-magnitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataExtractor:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data_path = os.getenv('DATASET_PATH')\n",
    "        self.data = self.extractData()\n",
    "\n",
    "    def extractData(self):\n",
    "        '''\n",
    "        Loads a dataset with product data from a specified path.\n",
    "        '''\n",
    "\n",
    "        return pd.read_csv(self.data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-portable",
   "metadata": {},
   "source": [
    "#  2. Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-telling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFormatter().categoryToDummy().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-coordinate",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFormatter().split_train_test_validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funky-memory",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataFormatter(dataExtractor):\n",
    "    def __init__(self):\n",
    "        self.extracted_data = dataExtractor().data\n",
    "        #self.train_data = self.formatData()[0]\n",
    "        #self.validation_data = self.formatData()[1]\n",
    "        \n",
    "    def formatData(self):\n",
    "        '''\n",
    "        Processes the dataset to use it for training and validation.\n",
    "        '''\n",
    "        \n",
    "        # add methods to formating the data to the  modeler.\n",
    "    \n",
    "    def categoryToDummy(self):\n",
    "        # get dummy\n",
    "        dummy = pd.get_dummies(self.extracted_data['category'])\n",
    "\n",
    "        # merge df\n",
    "        df_dummy = pd.merge(self.extracted_data, dummy, left_index=True, right_index=True)\n",
    "\n",
    "        # delet no dummy cols\n",
    "        del df_dummy['category']\n",
    "\n",
    "        return df_dummy\n",
    "    \n",
    "    def split_train_test_validate(self):\n",
    "        '''\n",
    "        Split the dataset into train, validation and test\n",
    "        '''\n",
    "        \n",
    "        # categorical variables list to split\n",
    "        return list(self.data.columns[-6:])\n",
    "        \n",
    "        # full data categorized\n",
    "        \n",
    "        #X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.2, train_size=0.8)\n",
    "        #X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.25,train_size =0.75)\n",
    "        \n",
    "        #return (X, y), (X_train, y_train), (x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aggressive-schema",
   "metadata": {},
   "source": [
    "# 3. Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "therapeutic-preservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataModeler(dataFormatter):\n",
    "    def __init__(self):\n",
    "        self.model = dataModeler.getModel()\n",
    "        self.train_data = dataFormatter.train_data\n",
    "        \n",
    "    def getModel():\n",
    "        '''\n",
    "        Specifies a model to handle the categorization problem.\n",
    "        # criar etapa de modelagem -métodos se for o caso\n",
    "        # dar split no train e treinar\n",
    "        \n",
    "        \n",
    "        '''\n",
    "\n",
    "        model = None\n",
    "        return model\n",
    "        \n",
    "    def writeModel(self):\n",
    "        '''\n",
    "        Exports a candidate model to a specified path available\n",
    "        in the environment variable MODEL_PATH.\n",
    "        '''\n",
    "\n",
    "        # criar try: tenta salvar, se nao dá erro.\n",
    "    \n",
    "        return pickle.dump(self.model, open(os.getenv('MODEL_PATH'),'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-going",
   "metadata": {},
   "source": [
    "# 4. Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electoral-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelValidator(dataModeler, dataFormatter):\n",
    "    def __init__(self):\n",
    "        self.model = self.readModel()\n",
    "        self.validation_data = dataFormatter.validation_data\n",
    "    \n",
    "    def readModel(self):\n",
    "        '''\n",
    "        get the model selected to handle the categorization problem.\n",
    "        '''\n",
    "        \n",
    "        # criar um try, se nao der entao dar um saveModel\n",
    "        \n",
    "        return pickle.load(open(os.getenv('MODEL_PATH'),'rb'))\n",
    "        \n",
    "    def validateModel(self):\n",
    "        '''\n",
    "        Generates metrics about the model accuracy (precision, recall, F1, etc.)\n",
    "        for each category and exports them to a specified path available in the \n",
    "        environment variable METRICS_PATH.\n",
    "        '''\n",
    "        # try k-fold and variants.\n",
    "        \n",
    "        # should save metrics in METRICS_PATH\n",
    "        f = open(os.getenv('METRICS_PATH'), \"w\")\n",
    "        f.write(\"F1:95.0, Precision:87.5\")\n",
    "        f.close()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-valve",
   "metadata": {},
   "source": [
    "# 5. Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExtractor().extractData().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataExtractor().extractData().category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "induced-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFormatter().categoryToDummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flying-patch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-wells",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataExtractor().extractData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alert-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df, dummy_df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solid-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-procedure",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(left, right, how=\"left\", on=[\"key1\", \"key2\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
